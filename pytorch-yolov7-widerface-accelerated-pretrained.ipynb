{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T21:58:09.392127Z",
     "iopub.status.busy": "2022-12-18T21:58:09.391712Z",
     "iopub.status.idle": "2022-12-18T21:58:49.413652Z",
     "shell.execute_reply": "2022-12-18T21:58:49.411977Z",
     "shell.execute_reply.started": "2022-12-18T21:58:09.392047Z"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/pankratozzi/Yolov7-training\n",
    "!pip install -qq pytorch_accelerated func_to_script pycocotools\n",
    "    \n",
    "import sys\n",
    "sys.path.append(\"/kaggle/working/Yolov7-training/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T21:58:49.418950Z",
     "iopub.status.busy": "2022-12-18T21:58:49.418637Z",
     "iopub.status.idle": "2022-12-18T21:58:53.617273Z",
     "shell.execute_reply": "2022-12-18T21:58:53.616293Z",
     "shell.execute_reply.started": "2022-12-18T21:58:49.418923Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import trange\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "\n",
    "import random\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "from func_to_script import script\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from pytorch_accelerated.callbacks import (\n",
    "    TrainerCallback,\n",
    "    EarlyStoppingCallback,\n",
    "    ModelEmaCallback,\n",
    "    ProgressBarCallback,\n",
    "    SaveBestModelCallback,\n",
    "    get_default_callbacks,\n",
    ")\n",
    "\n",
    "from pytorch_accelerated.utils import local_process_zero_only\n",
    "from pytorch_accelerated.schedulers import CosineLrScheduler\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from yolov7 import create_yolov7_model\n",
    "from yolov7.dataset import (\n",
    "    Yolov7Dataset,\n",
    "    create_base_transforms,\n",
    "    create_yolov7_transforms,\n",
    "    yolov7_collate_fn,\n",
    ")\n",
    "from yolov7.evaluation import CalculateMeanAveragePrecisionCallback\n",
    "from yolov7.loss_factory import create_yolov7_loss\n",
    "from yolov7.mosaic import MosaicMixupDataset, create_post_mosaic_transform\n",
    "from yolov7.trainer import Yolov7Trainer, filter_eval_predictions\n",
    "from yolov7.utils import SaveBatchesCallback, Yolov7ModelEma\n",
    "\n",
    "from yolov7.plotting import show_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T21:58:53.619563Z",
     "iopub.status.busy": "2022-12-18T21:58:53.618795Z",
     "iopub.status.idle": "2022-12-18T21:58:53.628933Z",
     "shell.execute_reply": "2022-12-18T21:58:53.627873Z",
     "shell.execute_reply.started": "2022-12-18T21:58:53.619527Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T21:58:53.632691Z",
     "iopub.status.busy": "2022-12-18T21:58:53.631921Z",
     "iopub.status.idle": "2022-12-18T21:58:53.694204Z",
     "shell.execute_reply": "2022-12-18T21:58:53.693247Z",
     "shell.execute_reply.started": "2022-12-18T21:58:53.632629Z"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device.upper()} device.\")\n",
    "\n",
    "root = \"/kaggle/input/wider-data/WIDER/\"\n",
    "pretrained = True  # True to get COCO weights\n",
    "image_size = 640\n",
    "batch_size = 2\n",
    "num_epochs = 16\n",
    "num_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T21:58:53.696241Z",
     "iopub.status.busy": "2022-12-18T21:58:53.695699Z",
     "iopub.status.idle": "2022-12-18T21:59:12.873352Z",
     "shell.execute_reply": "2022-12-18T21:59:12.872299Z",
     "shell.execute_reply.started": "2022-12-18T21:58:53.696206Z"
    }
   },
   "outputs": [],
   "source": [
    "model = create_yolov7_model(\n",
    "        architecture=\"yolov7\", num_classes=num_classes, pretrained=pretrained\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T21:59:12.875598Z",
     "iopub.status.busy": "2022-12-18T21:59:12.875192Z",
     "iopub.status.idle": "2022-12-18T21:59:12.887269Z",
     "shell.execute_reply": "2022-12-18T21:59:12.884368Z",
     "shell.execute_reply.started": "2022-12-18T21:59:12.875563Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_annots(file, max_faces=20):\n",
    "    def get_coords(line):\n",
    "        coor = line.split(\" \")\n",
    "        xywh = [int(coor[i]) for i in range(4)] if(len(coor) > 4) else None\n",
    "        return xywh\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    with open(file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for i, line in enumerate(lines):\n",
    "            if \".jpg\" in line:\n",
    "                annot = {\n",
    "                    \"path\": line.strip(),\n",
    "                    \"box_num\": int(lines[i+1]),\n",
    "                    \"boxes\": [],\n",
    "                    \"label\": [],\n",
    "                }\n",
    "                if max_faces >= annot[\"box_num\"]:\n",
    "                    for j in range(annot[\"box_num\"]):\n",
    "                        box = get_coords(lines[i+2+j].replace(\"\\n\", \"\"))\n",
    "                        if box is not None:\n",
    "                            x,y,w,h = box\n",
    "                            \n",
    "                            # xmin, ymin, xmax, ymax\n",
    "                            box = [x, y, x+w, y+h]\n",
    "                            annot[\"boxes\"].append(box)\n",
    "                            annot[\"label\"].append(0)  # 1\n",
    "                    if len(annot[\"boxes\"]) > 0:\n",
    "                        data.append(annot)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T21:59:12.889456Z",
     "iopub.status.busy": "2022-12-18T21:59:12.889067Z",
     "iopub.status.idle": "2022-12-18T21:59:13.348640Z",
     "shell.execute_reply": "2022-12-18T21:59:13.347549Z",
     "shell.execute_reply.started": "2022-12-18T21:59:12.889413Z"
    }
   },
   "outputs": [],
   "source": [
    "train = read_annots(\"../input/wider-data/WIDER/wider_face_train_bbx_gt.txt\")\n",
    "valid = read_annots(\"../input/wider-data/WIDER/wider_face_val_bbx_gt.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T21:59:13.350916Z",
     "iopub.status.busy": "2022-12-18T21:59:13.350186Z",
     "iopub.status.idle": "2022-12-18T21:59:13.484604Z",
     "shell.execute_reply": "2022-12-18T21:59:13.483521Z",
     "shell.execute_reply.started": "2022-12-18T21:59:13.350877Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame.from_records(train, columns=list(train[0].keys())).explode(\"boxes\").reset_index(drop=True)\n",
    "train_points = pd.DataFrame(x_train[\"boxes\"].values.tolist(), columns=[\"xmin\", \"ymin\", \"xmax\", \"ymax\"], index=x_train.index)\n",
    "x_train = pd.concat([x_train, train_points], axis=1)\n",
    "x_train = x_train[~((x_train.xmin == x_train.xmax) | (x_train.ymin == x_train.ymax))]\n",
    "x_train[\"class_id\"] = 0\n",
    "image_ids = {p: i for i, p in enumerate(x_train[\"path\"].unique())}\n",
    "x_train[\"image_id\"] = x_train[\"path\"].map(image_ids)\n",
    "\n",
    "x_train[\"w\"] = x_train[\"xmax\"] - x_train[\"xmin\"]\n",
    "x_train[\"h\"] = x_train[\"ymax\"] - x_train[\"ymin\"]\n",
    "\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T21:59:13.486533Z",
     "iopub.status.busy": "2022-12-18T21:59:13.486003Z",
     "iopub.status.idle": "2022-12-18T21:59:13.539651Z",
     "shell.execute_reply": "2022-12-18T21:59:13.538631Z",
     "shell.execute_reply.started": "2022-12-18T21:59:13.486497Z"
    }
   },
   "outputs": [],
   "source": [
    "x_valid = pd.DataFrame.from_records(valid, columns=list(train[0].keys())).explode(\"boxes\").reset_index(drop=True)\n",
    "valid_points = pd.DataFrame(x_valid[\"boxes\"].values.tolist(), columns=[\"xmin\", \"ymin\", \"xmax\", \"ymax\"], index=x_valid.index)\n",
    "x_valid = pd.concat([x_valid, valid_points], axis=1)\n",
    "x_valid = x_valid[~((x_valid.xmin == x_valid.xmax) | (x_valid.ymin == x_valid.ymax))]\n",
    "\n",
    "x_valid[\"class_id\"] = 0\n",
    "image_ids = {p: i for i, p in enumerate(x_valid[\"path\"].unique())}\n",
    "x_valid[\"image_id\"] = x_valid[\"path\"].map(image_ids)\n",
    "\n",
    "x_valid[\"w\"] = x_valid[\"xmax\"] - x_valid[\"xmin\"]\n",
    "x_valid[\"h\"] = x_valid[\"ymax\"] - x_valid[\"ymin\"]\n",
    "\n",
    "x_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T21:59:13.543873Z",
     "iopub.status.busy": "2022-12-18T21:59:13.543599Z",
     "iopub.status.idle": "2022-12-18T21:59:16.678594Z",
     "shell.execute_reply": "2022-12-18T21:59:16.677566Z",
     "shell.execute_reply.started": "2022-12-18T21:59:13.543849Z"
    }
   },
   "outputs": [],
   "source": [
    "test_paths = glob(\"../input/wider-data/WIDER/WIDER_test/\"+\"*/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T21:59:16.680645Z",
     "iopub.status.busy": "2022-12-18T21:59:16.680189Z",
     "iopub.status.idle": "2022-12-18T22:01:35.240244Z",
     "shell.execute_reply": "2022-12-18T22:01:35.239119Z",
     "shell.execute_reply.started": "2022-12-18T21:59:16.680609Z"
    }
   },
   "outputs": [],
   "source": [
    "from yolov7.anchors import (calculate_resized_gt_wh, \n",
    "                            calculate_resized_gt_wh, \n",
    "                            calculate_best_possible_recall,\n",
    "                            calculate_best_anchor_ratio, \n",
    "                            estimate_anchors\n",
    "                           )\n",
    "from scipy.cluster.vq import kmeans\n",
    "LOSS_ANCHOR_MULTIPLE_THRESHOLD = 4.0\n",
    "\n",
    "\n",
    "def find_image_sizes(path):\n",
    "    image = Image.open(root+\"WIDER_train/\"+path)\n",
    "    image = np.array(image)\n",
    "    return path, (image.shape[1], image.shape[0])\n",
    "\n",
    "image_sizes = process_map(find_image_sizes, [path for path in x_train.path.unique()])\n",
    "\n",
    "image_sizes_df = pd.DataFrame(dict(image_sizes)).T.reset_index().rename(columns={\"index\": \"path\", 0: \"image_w\", 1: \"image_h\"})\n",
    "x_train = x_train.merge(image_sizes_df, on=\"path\", how=\"left\")\n",
    "\n",
    "# use one bbox from image to calculate anchors, otherwise dims in gt_wh and image_sizes don't match\n",
    "raw_gt_wh = x_train.groupby(\"path\").agg({\"w\": \"last\", \"h\": \"last\"}).values\n",
    "image_sizes = image_sizes_df.groupby(\"path\").agg({\"image_w\": \"last\", \"image_h\": \"last\"}).values\n",
    "\n",
    "gt_wh = calculate_resized_gt_wh(raw_gt_wh, image_sizes, target_image_size=640)\n",
    "\n",
    "current_anchors = model.detection_head.anchor_grid.clone().cpu().view(-1, 2)\n",
    "\n",
    "recall = calculate_best_possible_recall(current_anchors, gt_wh)\n",
    "print(f\"Best possible recall with given images: {recall.item()}\")\n",
    "\n",
    "if recall < 0.98:\n",
    "\n",
    "    proposed_anchors = estimate_anchors(9, gt_wh)\n",
    "    recall = calculate_best_possible_recall(proposed_anchors, gt_wh)\n",
    "    print(f\"Best possible new recall with given images: {recall.item()}\")\n",
    "\n",
    "    model.update_anchors(np.sort(proposed_anchors, axis=0))  # sort as inbuilt method throws error\n",
    "else:\n",
    "    print(f\"Default anchors are suitable for this task.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T22:01:35.242745Z",
     "iopub.status.busy": "2022-12-18T22:01:35.242054Z",
     "iopub.status.idle": "2022-12-18T22:01:35.252872Z",
     "shell.execute_reply": "2022-12-18T22:01:35.251586Z",
     "shell.execute_reply.started": "2022-12-18T22:01:35.242705Z"
    }
   },
   "outputs": [],
   "source": [
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, data, train=True, transforms=None):\n",
    "        self.annotations_df = data\n",
    "        self.transforms = transforms\n",
    "        self.sub_path = \"WIDER_train/\" if train else \"WIDER_val/\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.annotations_df.image_id.nunique()\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        image_id = self.annotations_df[\"image_id\"].unique()[ix]\n",
    "        image_info = self.annotations_df[self.annotations_df.image_id == image_id]\n",
    "        path = image_info[\"path\"].iloc[0]\n",
    "        \n",
    "        image = Image.open(root + self.sub_path + path).convert(\"RGB\")\n",
    "        image = np.array(image)\n",
    "        image_hw = image.shape[:2]\n",
    "\n",
    "        xyxy_bboxes = image_info[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n",
    "        class_ids = image_info[\"class_id\"].values\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            transformed = self.transforms(\n",
    "                image=image, bboxes=xyxy_bboxes, labels=class_ids\n",
    "            )\n",
    "            image = transformed[\"image\"]\n",
    "            xyxy_bboxes = np.array(transformed[\"bboxes\"])\n",
    "            class_ids = np.array(transformed[\"labels\"])\n",
    "\n",
    "        return image, xyxy_bboxes, class_ids, image_id, image_hw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T22:01:35.254944Z",
     "iopub.status.busy": "2022-12-18T22:01:35.254479Z",
     "iopub.status.idle": "2022-12-18T22:01:35.268856Z",
     "shell.execute_reply": "2022-12-18T22:01:35.267851Z",
     "shell.execute_reply.started": "2022-12-18T22:01:35.254912Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = FaceDataset(x_train, transforms=create_base_transforms(image_size))\n",
    "valid_ds = FaceDataset(x_valid, train=False)\n",
    "\n",
    "mds = MosaicMixupDataset(\n",
    "        train_ds,\n",
    "        apply_mixup_probability=0.15,\n",
    "        post_mosaic_transforms=create_post_mosaic_transform(\n",
    "        output_height=image_size, output_width=image_size\n",
    "        ),\n",
    "    )\n",
    "if pretrained:\n",
    "    # disable mosaic if finetuning\n",
    "    mds.disable()\n",
    "    \n",
    "train_yds = Yolov7Dataset(\n",
    "    mds,\n",
    "    create_yolov7_transforms(training=True, image_size=(image_size, image_size)),\n",
    ")\n",
    "eval_yds = Yolov7Dataset(\n",
    "    valid_ds,\n",
    "    create_yolov7_transforms(training=False, image_size=(image_size, image_size)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T22:01:35.272195Z",
     "iopub.status.busy": "2022-12-18T22:01:35.271362Z",
     "iopub.status.idle": "2022-12-18T22:01:35.336307Z",
     "shell.execute_reply": "2022-12-18T22:01:35.335435Z",
     "shell.execute_reply.started": "2022-12-18T22:01:35.272111Z"
    }
   },
   "outputs": [],
   "source": [
    "param_groups = model.get_parameter_groups()\n",
    "\n",
    "loss_func = create_yolov7_loss(model, image_size=image_size)\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    param_groups[\"other_params\"], lr=0.01, momentum=0.9, nesterov=True  # 0.937\n",
    ")\n",
    "\n",
    "calculate_map_callback = (\n",
    "    CalculateMeanAveragePrecisionCallback.create_from_targets_df(\n",
    "        targets_df=x_valid[\n",
    "            [\"image_id\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"class_id\"]\n",
    "        ],\n",
    "        image_ids=set(x_valid.image_id.unique()),\n",
    "        iou_threshold=0.2,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T22:31:19.027897Z",
     "iopub.status.busy": "2022-12-18T22:31:19.027507Z",
     "iopub.status.idle": "2022-12-18T22:31:19.038016Z",
     "shell.execute_reply": "2022-12-18T22:31:19.036778Z",
     "shell.execute_reply.started": "2022-12-18T22:31:19.027866Z"
    }
   },
   "outputs": [],
   "source": [
    "class PlotImageCallback(TrainerCallback):\n",
    "    def __init__(self, image_paths):\n",
    "        self.image_paths = image_paths\n",
    "        \n",
    "    def plot_image(self):\n",
    "        idx = np.random.randint(len(self.image_paths))\n",
    "        path = self.image_paths[idx]\n",
    "        image = Image.open(path).convert(\"RGB\").resize((image_size, image_size))\n",
    "        image = np.array(image)\n",
    "        image_tensor = torch.FloatTensor(image / 255.).permute(2,0,1).unsqueeze(0).to(device)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(image_tensor)\n",
    "        output = model.postprocess(out, conf_thres=0.001, max_detections=100, multiple_labels_per_box=True)  # postprocess 3 fpn outputs\n",
    "        output = filter_eval_predictions(output, confidence_threshold=0.2, nms_threshold=0.65)  # nms\n",
    "        output = output[0].cpu().detach().numpy()\n",
    "        boxes = output[:, :4].tolist()\n",
    "        labels = output[:, -1].astype(int).tolist()\n",
    "\n",
    "        show_image(image, bboxes=boxes, \n",
    "                   class_labels=[\"face\"]*len(boxes), \n",
    "                   bbox_format=\"xyxy\")\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "    def on_eval_epoch_end(self, trainer, **kwargs):\n",
    "        self.plot_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T22:01:35.351071Z",
     "iopub.status.busy": "2022-12-18T22:01:35.350656Z",
     "iopub.status.idle": "2022-12-18T22:01:35.359423Z",
     "shell.execute_reply": "2022-12-18T22:01:35.358097Z",
     "shell.execute_reply.started": "2022-12-18T22:01:35.351038Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Yolov7Trainer(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        loss_func=loss_func,\n",
    "        filter_eval_predictions_fn=partial(\n",
    "            filter_eval_predictions, confidence_threshold=0.01, nms_threshold=0.3\n",
    "        ),\n",
    "        callbacks=[\n",
    "                    PlotImageCallback(test_paths),\n",
    "                    calculate_map_callback,\n",
    "                    ModelEmaCallback(\n",
    "                        decay=0.9999,\n",
    "                        model_ema=Yolov7ModelEma,\n",
    "                        callbacks=[ProgressBarCallback, calculate_map_callback],\n",
    "                    ),\n",
    "                    SaveBestModelCallback(watch_metric=\"map\", greater_is_better=True),\n",
    "                    SaveBatchesCallback(\"./batches\", num_images_per_batch=2),\n",
    "                    EarlyStoppingCallback(\n",
    "                        early_stopping_patience=3,\n",
    "                        watch_metric=\"map\",\n",
    "                        greater_is_better=True,\n",
    "                        early_stopping_threshold=0.001,\n",
    "                    ),\n",
    "                    *get_default_callbacks(progress_bar=False),  # True \n",
    "                ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T22:01:35.361611Z",
     "iopub.status.busy": "2022-12-18T22:01:35.361183Z",
     "iopub.status.idle": "2022-12-18T22:01:35.372030Z",
     "shell.execute_reply": "2022-12-18T22:01:35.371044Z",
     "shell.execute_reply.started": "2022-12-18T22:01:35.361578Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate scaled weight decay and gradient accumulation steps (simulates larger batch size)\n",
    "total_batch_size = (\n",
    "    batch_size * trainer._accelerator.num_processes\n",
    ")  # batch size across all processes\n",
    "\n",
    "nominal_batch_size = 64\n",
    "num_accumulate_steps = max(round(nominal_batch_size / total_batch_size), 1)\n",
    "base_weight_decay = 0.0005\n",
    "scaled_weight_decay = (\n",
    "    base_weight_decay * total_batch_size * num_accumulate_steps / nominal_batch_size\n",
    ")\n",
    "\n",
    "optimizer.add_param_group(\n",
    "    {\"params\": param_groups[\"conv_weights\"], \"weight_decay\": scaled_weight_decay}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T22:01:35.374042Z",
     "iopub.status.busy": "2022-12-18T22:01:35.373549Z",
     "iopub.status.idle": "2022-12-18T22:28:15.606044Z",
     "shell.execute_reply": "2022-12-18T22:28:15.604354Z",
     "shell.execute_reply.started": "2022-12-18T22:01:35.374008Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.train(\n",
    "        num_epochs=num_epochs,\n",
    "        train_dataset=train_yds,\n",
    "        eval_dataset=eval_yds,\n",
    "        per_device_batch_size=batch_size,\n",
    "        create_scheduler_fn=CosineLrScheduler.create_scheduler_fn(\n",
    "            num_warmup_epochs=2,  # 5\n",
    "            num_cooldown_epochs=2,  # 5\n",
    "            k_decay=2,\n",
    "        ),\n",
    "        collate_fn=yolov7_collate_fn,\n",
    "        gradient_accumulation_steps=num_accumulate_steps,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-18T22:31:33.583587Z",
     "iopub.status.busy": "2022-12-18T22:31:33.582301Z",
     "iopub.status.idle": "2022-12-18T22:31:38.739075Z",
     "shell.execute_reply": "2022-12-18T22:31:38.738291Z",
     "shell.execute_reply.started": "2022-12-18T22:31:33.583537Z"
    }
   },
   "outputs": [],
   "source": [
    "plotter = PlotImageCallback(test_paths)\n",
    "\n",
    "for _ in range(10):\n",
    "    plotter.plot_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [SEE RESULTS: param tunning needed + more epochs](https://www.kaggle.com/code/pankratozzi/pytorch-yolov7-widerface-accelerated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
